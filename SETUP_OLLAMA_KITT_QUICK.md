# Setup Rapide : KITT + Ollama Cloud

## √âtape 1 : Installation Ollama (en cours...)

T√©l√©chargement de 1 Go en cours (~1 heure restant).

---

## √âtape 2 : Configuration Ollama (apr√®s installation)

Une fois Ollama install√©, dans un terminal :

```bash
# 1. Se connecter √† Ollama Cloud
ollama signin
# ‚Üí Cr√©er un compte sur ollama.com si besoin

# 2. Tester un mod√®le cloud gratuit
ollama run gpt-oss:20b-cloud

# Si √ßa fonctionne, vous verrez :
# >>> send a message... (or '/help' for commands)
```

**Mod√®les cloud gratuits recommand√©s :**
- `gpt-oss:20b-cloud` (20B) - Bon √©quilibre
- `glm-4.6:cloud` (4B) - Rapide
- `kimi-k2:1t-cloud` (1T !) - Gigantesque mais gratuit

---

## √âtape 3 : Trouver l'IP de votre PC

**Windows :**
```powershell
ipconfig
# ‚Üí Cherchez "IPv4 Address" sous votre adaptateur WiFi/Ethernet
# Exemple : 192.168.1.100
```

**Mac/Linux :**
```bash
ifconfig
# OU
ip addr show
# ‚Üí Cherchez une IP commen√ßant par 192.168.x.x ou 10.0.x.x
```

**Notez cette IP** : `__________` (vous en aurez besoin)

---

## √âtape 4 : Configuration KITT

Une fois Ollama fonctionnel, configurez KITT avec cette commande :

```bash
# Remplacer VOTRE_IP par celle trouv√©e √† l'√©tape 3
# Remplacer VOTRE_MODEL par celui que vous voulez (ex: gpt-oss:20b-cloud)

adb shell "run-as com.chatai sh -c 'cd shared_prefs && cat > chatai_ai_config.xml << EOF
<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\" standalone=\\\"yes\\\" ?>
<map>
    <string name=\\\"local_server_url\\\">http://192.168.1.100:11434/v1/chat/completions</string>
    <string name=\\\"local_model_name\\\">gpt-oss:20b-cloud</string>
</map>
EOF
'"
```

**Modifiez les valeurs :**
- `192.168.1.100` ‚Üí votre IP trouv√©e √† l'√©tape 3
- `gpt-oss:20b-cloud` ‚Üí le mod√®le Ollama que vous voulez

---

## √âtape 5 : Red√©marrer ChatAI

```bash
adb shell am force-stop com.chatai
adb shell monkey -p com.chatai -c android.intent.category.LAUNCHER 1
```

---

## √âtape 6 : Tester KITT

1. **Ouvrir ChatAI** sur votre t√©l√©phone
2. **Aller dans Configuration ‚Üí IA**
3. **Cliquer "TESTER LES APIS"**

Dans les logs d√©taill√©s, vous devriez voir :

```
[3] Local Server: Attempting...
    - URL: http://192.168.1.100:11434/v1/chat/completions
    - Model: gpt-oss:20b-cloud
    - HTTP response: 200
    - Response: Certainly, Michael. I am ready...
[3] Local Server: SUCCESS
```

**KITT devrait r√©pondre avec l'intelligence d'Ollama !** üéâ

---

## D√©pannage

### "Connection refused" ou timeout
‚ûú V√©rifiez que :
- Ollama est d√©marr√© (`ollama serve`)
- L'IP est correcte
- T√©l√©phone et PC sur le m√™me WiFi
- Firewall Windows ne bloque pas le port 11434

### "Model not found"
‚ûú Le mod√®le n'est pas install√©. Faites :
```bash
ollama pull gpt-oss:20b-cloud
```

### "HTTP 404"
‚ûú URL incorrecte. Format correct :
```
http://IP:11434/v1/chat/completions
```

### Ollama ne r√©pond pas
‚ûú V√©rifiez que le serveur est actif :
```bash
# Dans un terminal
ollama serve
```

---

## Commandes Ollama utiles

```bash
# Lister les mod√®les install√©s
ollama list

# T√©l√©charger un mod√®le
ollama pull nom-du-modele

# Ex√©cuter un mod√®le interactif
ollama run nom-du-modele

# Stopper le serveur
# Ctrl+C dans le terminal o√π ollama serve tourne
```

---

## Prochaines √©tapes (optionnel)

Une fois que tout fonctionne, je peux :
1. ‚úÖ Ajouter une interface graphique pour configurer facilement
2. ‚úÖ Ajouter un bouton "Test Ollama" dans les r√©glages
3. ‚úÖ Afficher le statut du serveur local dans l'app
4. ‚úÖ G√©rer plusieurs mod√®les (switch rapide)

---

**Pendant le t√©l√©chargement d'Ollama, je peux commencer l'interface graphique si vous voulez !**

