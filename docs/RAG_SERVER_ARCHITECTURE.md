# ChatAI RAG Server - Architecture

**Date:** 2025-11-06  
**Status:** PLANIFI√â v5.0.0  
**Location:** Serveur PC Python (port 8890)

---

## üéØ VISION

**Serveur de calculs lourds pour ChatAI:**
- Embeddings (sentence-transformers)
- Recherche s√©mantique conversations
- D√©tection corrections automatique
- Analyse patterns utilisateur

**But:** Offloader calculs lourds du device Android vers PC puissant.

---

## üèóÔ∏è ARCHITECTURE √âCOSYST√àME COMPLET

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ANDROID DEVICE (ChatAI)                                ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ HttpServer (port 8080) - Interface web ChatAI      ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ WebServer (port 8888) - GameLibrary/Arcade         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ ChatAI App - KITT vocal + Interface                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì R√©seau local (WiFi/Hotspot)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PC SERVEURS (Calculs lourds)                           ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Ollama Local (port 11434) - LLM local              ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ Mod√®les: llama3, qwen, etc.                    ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ RAG Server (port 8890) - Embeddings/Search         ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ Python Flask + sentence-transformers          ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ CPU: Embeddings rapides                        ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ RAM: Cache embeddings                          ‚îÇ
‚îÇ  ‚îÇ                                                       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ GPU (optionnel) - Calculs ML lourds                ‚îÇ
‚îÇ      ‚îî‚îÄ‚îÄ Fine-tuning, Training, etc.                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚Üì Internet
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CLOUD (Ollama Cloud)                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ LLM Cloud (120B, 480B, 671B)                       ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Web Search API                                     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Tool Calling, Thinking, Vision                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üì° RAG SERVER - D√âTAILS TECHNIQUES

### **Stack:**
- **Framework:** Flask (Python)
- **Mod√®le:** `all-MiniLM-L6-v2` (SentenceTransformers)
- **Dimension:** 384 embeddings
- **Taille:** 80 MB (l√©ger et rapide)
- **Port:** 8890

### **Fichier:** `chatai_rag_server.py`

**Localisation:**
- Backup: `BACKUP_v2.9_20251102_021947/chatai_rag_server.py`
- Status: Fonctionnel mais pas int√©gr√© √† v4.7.0

---

## üîß ENDPOINTS API

### **1. GET /** (Home)
```
Status page HTML
- Model info
- Endpoints list
- Usage examples
```

### **2. GET /status**
```json
Response: {
  "status": "online",
  "model": "all-MiniLM-L6-v2",
  "embedding_dimension": 384,
  "cache_size": 150,
  "conversations_loaded": 42,
  "timestamp": "2025-11-06T00:54:00"
}
```

### **3. POST /embed**
```json
Request: {
  "text": "Quelle heure √† Tokyo?"
}

Response: {
  "embedding": [0.123, -0.456, ...],  // 384 floats
  "dimension": 384,
  "cached": false
}
```

**Usage:** G√©n√©rer embedding pour un texte

### **4. POST /search**
```json
Request: {
  "query": "Quelle heure √† Tokyo?",
  "conversations": [
    {"userMessage": "...", "aiResponse": "..."},
    ...
  ],
  "top_k": 5
}

Response: {
  "results": [
    {
      "conversation": {...},
      "score": 0.92
    },
    {
      "conversation": {...},
      "score": 0.87
    },
    ...
  ],
  "query": "...",
  "total_scanned": 42
}
```

**Usage:** Recherche s√©mantique - trouve conversations similaires

### **5. POST /detect_correction**
```json
Request: {
  "text": "Non, Tokyo est UTC+9 pas UTC-5"
}

Response: {
  "is_correction": true,
  "confidence": 0.89,
  "correction_type": "factual_error",
  "keywords_found": ["non", "pas"]
}
```

**Usage:** D√©tection auto-corrections utilisateur

### **6. POST /analyze**
```json
Request: {
  "conversation": {
    "userMessage": "...",
    "aiResponse": "...",
    "thinkingTrace": "..."
  }
}

Response: {
  "sentiment": "positive",
  "topics": ["time", "timezone", "calculation"],
  "confidence": 0.95,
  "suggestions": [...]
}
```

**Usage:** Analyse conversation pour patterns/am√©lioration

---

## üöÄ WORKFLOW RAG COMPLET (v5.0.0)

### **Scenario: Question utilisateur**

```kotlin
// ChatAI Android
val userInput = "Quelle heure √† Tokyo?"

// 1. G√©n√©rer embedding de la question
val embedding = ragServerClient.embed(userInput)
// ‚Üí POST http://PC_IP:8890/embed

// 2. Rechercher conversations similaires
val similarConvs = ragServerClient.search(
    query = userInput,
    conversations = conversationDao.getAll(),
    topK = 5
)
// ‚Üí POST http://PC_IP:8890/search
// ‚Üí Retourne: 5 conversations les plus pertinentes

// 3. Construire contexte enrichi
val ragContext = """
[CONTEXTE RAG - Conversations similaires]
${similarConvs.joinToString("\n") { 
    "Q: ${it.userMessage}\nR: ${it.aiResponse}\nScore: ${it.score}"
}}
[FIN CONTEXTE RAG]
"""

// 4. Envoyer √† Ollama avec contexte
messages.put({
    "role": "user",
    "content": userInput + systemContext + ragContext
})

// 5. L'IA r√©pond avec m√©moire long terme!
// ‚Üí Se souvient de conversations pass√©es
// ‚Üí Coh√©rence sur longue p√©riode
// ‚Üí Apprentissage patterns utilisateur
```

---

## üìä B√âN√âFICES RAG

### **M√©moire Long Terme:**
```
Conversation 1 (il y a 2 semaines):
Q: "Tokyo c'est quel fuseau horaire?"
A: "UTC+9, Michael"

Conversation 100 (aujourd'hui):
Q: "Quelle heure √† Tokyo?"
  ‚Üí RAG trouve conversation 1 (score: 0.94)
  ‚Üí Contexte: "Tu as d√©j√† expliqu√© que Tokyo = UTC+9"
  ‚Üí R√©ponse coh√©rente avec historique ‚úÖ
```

### **Auto-Correction:**
```
User: "Tokyo c'est UTC-5"
KITT: "UTC+9, Michael"
User: "Non, je disais n'importe quoi, c'est UTC+9"
  ‚Üí RAG detecte correction (confidence: 0.91)
  ‚Üí Sauvegarde pattern: User autocorrection
  ‚Üí Apprentissage: User parfois teste KITT
```

### **Recherche S√©mantique:**
```
Query: "heure japon"
  ‚Üí Trouve conversations sur "Tokyo", "fuseau horaire", "Asie"
  ‚Üí M√™me si mots exacts diff√©rents
  ‚Üí Similarit√© s√©mantique (embeddings)
```

---

## üîß INT√âGRATION ANDROID (v5.0.0)

### **Nouvelle classe: RagServerClient.kt**

```kotlin
class RagServerClient(
    private val serverUrl: String, // http://PC_IP:8890
    private val httpClient: OkHttpClient
) {
    /**
     * G√©n√©rer embedding pour texte
     */
    suspend fun embed(text: String): FloatArray {
        val requestBody = JSONObject().apply {
            put("text", text)
        }
        
        val response = httpClient.post("$serverUrl/embed", requestBody)
        val embedding = response.getJSONArray("embedding")
        
        return FloatArray(embedding.length()) { i ->
            embedding.getDouble(i).toFloat()
        }
    }
    
    /**
     * Recherche s√©mantique
     */
    suspend fun search(
        query: String,
        conversations: List<ConversationEntity>,
        topK: Int = 5
    ): List<ConversationMatch> {
        val requestBody = JSONObject().apply {
            put("query", query)
            put("conversations", conversationsToJSON(conversations))
            put("top_k", topK)
        }
        
        val response = httpClient.post("$serverUrl/search", requestBody)
        return parseSearchResults(response)
    }
    
    /**
     * D√©tecter si message = correction
     */
    suspend fun detectCorrection(text: String): CorrectionResult {
        val response = httpClient.post("$serverUrl/detect_correction", ...)
        return CorrectionResult(
            isCorrection = response.getBoolean("is_correction"),
            confidence = response.getDouble("confidence"),
            type = response.getString("correction_type")
        )
    }
}
```

### **Int√©gration dans KittAIService:**

```kotlin
// Avant d'envoyer √† Ollama
if (ragServerAvailable()) {
    // Rechercher conversations pertinentes
    val similarConvs = ragClient.search(userInput, allConversations, 5)
    
    // Ajouter au contexte
    val ragContext = buildRagContext(similarConvs)
    messages.put({
        "role": "system",
        "content": ragContext
    })
}
```

---

## üìù D√âMARRAGE SERVEUR

<function_calls>
<invoke name="run_terminal_cmd">
<parameter name="command">Start-Sleep -Seconds 3 && curl http://localhost:8890/status
