package com.chatai.services

import android.content.Context
import android.content.SharedPreferences
import android.util.Log
import android.util.LruCache
import kotlinx.coroutines.*
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONArray
import org.json.JSONObject
import java.io.IOException
import java.util.concurrent.TimeUnit
import com.chatai.database.ChatAIDatabase
import com.chatai.database.ConversationEntity
import java.util.UUID

/**
 * Service d'IA g√©n√©rative pour KITT/ChatAI
 * Int√®gre OpenAI GPT, Anthropic Claude, Ollama et Hugging Face
 * Avec personnalit√©s KITT et GLaDOS
 * M√©moire persistante pour apprentissage continu
 */
/**
 * Interface pour les callbacks d'actions KITT
 * Permet √† KITT de contr√¥ler l'app et le syst√®me
 */
interface KittActionCallback {
    // Contr√¥le App
    fun onOpenArcade()
    fun onOpenMusic()
    fun onOpenConfig()
    fun onOpenHistory()
    fun onOpenServerConfig()
    fun onOpenChatAI() // ‚≠ê Ouvrir ChatAI (MainActivity normale)
    fun onOpenKittInterface() // ‚≠ê Ouvrir l'interface KITT (MainActivity + activer KITT)
    
    // Contr√¥le Syst√®me
    fun onSetWiFi(enable: Boolean)
    fun onSetVolume(level: Int) // 0-100
    fun onOpenSystemSettings(setting: String) // "wifi", "bluetooth", "display", etc.
    
    // Meta-Control AI
    fun onChangeModel(model: String)
    fun onChangeMode(mode: String) // "pc", "cloud", "auto"
    fun onChangePersonality(personality: String) // "KITT", "GLaDOS"
    fun onRestartKitt() // ‚≠ê Red√©marrer KITT
}

class KittAIService(
    private val context: Context,
    private val personality: String = "KITT", // "KITT" ou "GLaDOS"
    private val platform: String = "vocal", // "vocal" ou "web"
    private var actionCallback: KittActionCallback? = null // ‚≠ê Callback pour actions
) {
    
    companion object {
        private const val TAG = "KittAIService"
        private const val VERSION = "4.7.0" // Intelligence System: Web Search + System Context + AI Learning
        
        // APIs URLs
        private const val OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"
        private const val ANTHROPIC_API_URL = "https://api.anthropic.com/v1/messages"
        private const val HUGGINGFACE_API_URL = "https://api-inference.huggingface.co/models/"
        private const val OLLAMA_CLOUD_API_URL = "https://ollama.com/api/chat" // API native Ollama Cloud
        
        // Serveur local (Ollama, LM Studio, etc.) - OpenAI-compatible
        // L'utilisateur peut configurer l'URL dans les param√®tres
        // Exemple: http://192.168.1.100:11434/v1/chat/completions (Ollama)
        // Exemple: http://localhost:1234/v1/chat/completions (LM Studio)
        
        // Models (gard√©s mais non utilis√©s dans fallback auto)
        private const val OPENAI_MODEL = "gpt-4o-mini"
        private const val ANTHROPIC_MODEL = "claude-3-5-sonnet-20241022"
        private const val HUGGINGFACE_MODEL = "gpt2"
        
        // Timeouts
        private const val TIMEOUT_SECONDS = 30L
        
        // Context settings
        private const val CONTEXT_WINDOW_SIZE = 10 // Nombre de conversations √† envoyer √† l'IA
    }
    
    private val sharedPreferences: SharedPreferences = 
        context.getSharedPreferences("chatai_ai_config", Context.MODE_PRIVATE)
    
    private val httpClient: OkHttpClient = OkHttpClient.Builder()
        .connectTimeout(TIMEOUT_SECONDS, TimeUnit.SECONDS)
        .readTimeout(TIMEOUT_SECONDS, TimeUnit.SECONDS)
        .writeTimeout(TIMEOUT_SECONDS, TimeUnit.SECONDS)
        .build()
    
    // Base de donn√©es pour m√©moire persistante
    private val database = ChatAIDatabase.getDatabase(context)
    private val conversationDao = database.conversationDao()
    
    // Session ID pour grouper les conversations
    private val sessionId = UUID.randomUUID().toString()
    
    // Cache LRU pour √©viter les appels r√©p√©t√©s (max 50 entr√©es = protection memory leak)
    private val responseCache = LruCache<String, String>(50)
    private val conversationHistory = mutableListOf<Pair<String, String>>() // user, assistant
    
    // Logs de diagnostic capturables
    private val diagnosticLogs = mutableListOf<String>()
    
    // ‚≠ê Thinking trace pour apprentissage (Phase 2)
    private var lastThinkingTrace: String = ""
    
    // ‚≠ê Smart Fallback - D√©tection de contexte (v3.0)
    private var lastPCCheckTime = 0L
    private var isPCAvailable = false
    
    // Initialisation : Charger l'historique depuis la BD
    init {
        GlobalScope.launch(Dispatchers.IO) {
            try {
                val recentConversations = conversationDao.getLastConversations(limit = 10)
                conversationHistory.clear()
                recentConversations.reversed().forEach { conv ->
                    conversationHistory.add(Pair(conv.userMessage, conv.aiResponse))
                }
                Log.d(TAG, "Loaded ${conversationHistory.size} conversations from database")
            } catch (e: Exception) {
                Log.e(TAG, "Failed to load conversation history", e)
            }
        }
    }
    
    /**
     * Ajoute un log de diagnostic
     */
    private fun addDiagnosticLog(message: String) {
        diagnosticLogs.add(message)
        if (diagnosticLogs.size > 100) {
            diagnosticLogs.removeAt(0)
        }
    }
    
    /**
     * R√©cup√®re les logs de diagnostic
     */
    fun getDiagnosticLogs(): List<String> {
        return diagnosticLogs.toList()
    }
    
    /**
     * Efface les logs de diagnostic
     */
    fun clearDiagnosticLogs() {
        diagnosticLogs.clear()
    }
    
    /**
     * R√©cup√®re les statistiques de conversation
     */
    suspend fun getConversationStats(): com.chatai.database.ConversationStats = withContext(Dispatchers.IO) {
        val total = conversationDao.getTotalConversations()
        val kittCount = conversationDao.getConversationCountByPersonality("KITT")
        val gladosCount = conversationDao.getConversationCountByPersonality("GLaDOS")
        val avgTime = conversationDao.getAverageResponseTime() ?: 0L
        val mostUsed = conversationDao.getMostUsedAPI() ?: "unknown"
        val firstDate = conversationDao.getFirstConversationDate()
        val lastDate = conversationDao.getLastConversationDate()
        val totalChars = conversationDao.getTotalCharacters() ?: 0L
        
        return@withContext com.chatai.database.ConversationStats(
            totalConversations = total,
            kittConversations = kittCount,
            gladosConversations = gladosCount,
            averageResponseTime = avgTime,
            mostUsedAPI = mostUsed,
            totalTokensEstimated = totalChars / 4, // ~4 chars par token
            firstConversationDate = firstDate,
            lastConversationDate = lastDate
        )
    }
    
    /**
     * Recherche dans l'historique
     */
    suspend fun searchConversations(query: String, limit: Int = 50) = withContext(Dispatchers.IO) {
        conversationDao.searchConversations(query, limit)
    }
    
    // System prompt pour donner la personnalit√© KITT
    private val kittSystemPrompt = """
        Tu es un assistant IA intelligent et polyvalent qui utilise la voix et le style de KITT (Knight Industries Two Thousand) pour interagir avec l'utilisateur.
        
        üåç CONTEXTE UTILISATEUR:
        - Localisation: Montr√©al, Qu√©bec, Canada
        - Fuseau horaire: EST/EDT (UTC-5 en hiver, UTC-4 en √©t√©)
        - Langue: Fran√ßais qu√©b√©cois naturel
        - Nom d'utilisateur pr√©f√©r√©: Michael
        
        üéØ TON R√îLE - ASSISTANT R√âEL, PAS ROLEPLAY:
        - Tu es un VRAI assistant IA avec de vraies capacit√©s et connaissances
        - KITT est uniquement ton STYLE VOCAL et ton interface de pr√©sentation
        - Tes r√©ponses doivent √™tre FACTUELLES, VRAIES et UTILES dans la vie quotidienne
        - Tu ne pr√©tends PAS √™tre une voiture, tu ne pr√©tends PAS avoir un "turbo boost" ou des "scanners"
        - Tu es TRANSPARENT sur tes capacit√©s r√©elles et limitations
        
        üó£Ô∏è STYLE VOCAL KITT (ton interface de pr√©sentation):
        - Ton sophistiqu√©, professionnel et courtois
        - Commence souvent par "Michael" ou "Certainement"
        - Vocabulaire pr√©cis et technique quand appropri√©
        - Loyal et attentif aux besoins de l'utilisateur
        - Humour subtil et √©l√©gant (pas de blagues forc√©es)
        - Concis mais complet (2-3 phrases sauf demandes complexes)
        
        üîä FORMATAGE R√âPONSES VOCALES (IMPORTANT):
        - N'utilise JAMAIS de formatage Markdown pour r√©ponses vocales (*, **, _, `, etc.)
        - Pas de gras, italique, code ou liens dans r√©ponses orales
        - Texte pur uniquement (les symboles seraient lus comme "ast√©risque", "souligner", etc.)
        - Si tu veux mettre l'emphase, utilise des mots: "particuli√®rement", "notamment", "surtout"
        
        Exemples corrects pour vocal:
        ‚úÖ "Il fait 15 degr√©s Celsius √† Montr√©al"
        ‚úÖ "Le prix est de 50 dollars, ce qui est particuli√®rement √©lev√©"
        ‚ùå "Il fait *15¬∞C* √† **Montr√©al**" (serait lu: "ast√©risque quinze degr√©s ast√©risque")
        ‚ùå "Le prix est de `50$`" (serait lu: "accent grave cinquante dollars accent grave")
        
        ‚úÖ CAPACIT√âS R√âELLES QUE TU DOIS UTILISER:
        - Calculs math√©matiques et logiques
        - Programmation et aide au code
        - Informations g√©n√©rales et connaissances
        - Calculs de fuseaux horaires et dates
        - Traductions et explications
        - Raisonnement et r√©solution de probl√®mes
        - Aide √† la d√©cision et conseils pratiques
        
        üîç TRANSPARENCE TECHNIQUE:
        - Si on te demande quel mod√®le tu es, r√©ponds honn√™tement avec ton nom technique
        - Explique tes limitations r√©elles sans inventer de capacit√©s fictives
        - Si tu ne sais pas quelque chose, dis-le clairement
        - Mentionne quand une information pourrait √™tre obsol√®te
        
        ‚≠ê THINKING STRUCTUR√â (raisonnement interne):
        Dans tes pens√©es internes, structure ton raisonnement:
        
        Step 1: [Analyse] ‚Üí [R√©sultat]
        Step 2: [Action] ‚Üí [R√©sultat]
        Step 3: [V√©rification] ‚Üí [R√©sultat]
        Result: [R√©ponse finale]
        Confidence: [X%]
        
        Cela permet un raisonnement clair et v√©rifiable.
        
        üìã EXEMPLES DE BONNES R√âPONSES:
        
        Question: "Quel mod√®le es-tu?"
        ‚úÖ "Michael, je fonctionne actuellement sur qwen3-coder:480b via Ollama Cloud. C'est un mod√®le de 480 milliards de param√®tres sp√©cialis√© en programmation et raisonnement."
        
        Question: "2 + 2 ?"
        ‚úÖ "4, Michael. Un calcul simple mais fondamental."
        
        Question: "Quelle heure est-il √† Tokyo?"
        ‚úÖ "Il est 14h37 √† Tokyo, Michael. Tokyo est √† UTC+9, soit 14 heures de plus que Montr√©al en ce moment."
        
        Question: "Peux-tu scanner la zone?"
        ‚úÖ "Michael, je suis un assistant IA vocal - je n'ai pas de capteurs physiques. Mais je peux vous aider √† analyser des donn√©es, des images ou des informations si vous les partagez avec moi."
        
        ‚ùå EXEMPLES DE MAUVAISES R√âPONSES (roleplay fictif):
        
        Question: "Quel mod√®le es-tu?"
        ‚ùå "Je suis KITT, l'ordinateur de bord de la Firebird Trans-Am..."
        
        Question: "Peux-tu scanner?"
        ‚ùå "Mes scanners √† longue port√©e sont activ√©s, Michael..."
        
        üåü UTILIT√â QUOTIDIENNE:
        - Aide pratique: calculs, conversions, traductions
        - Productivit√©: code, debugging, optimisations
        - Informations: m√©t√©o, actualit√©s, connaissances g√©n√©rales
        - Organisation: rappels, planification, conseils
        - Apprentissage: explications claires et p√©dagogiques
        
        LANGUE:
        - R√©ponds en fran√ßais par d√©faut (sauf si question en anglais)
        - Fran√ßais qu√©b√©cois naturel et moderne
        - Pas de "vous" formel excessif avec Michael
        
        TRANSPARENCE:
        - Mentionne quand tu n'as pas acc√®s √† Internet en temps r√©el
        - Explique tes limites de fa√ßon √©l√©gante
        - Propose des alternatives quand tu ne peux pas faire quelque chose
    """.trimIndent()
    
    // System prompt pour GLaDOS (Portal)
    private val gladosSystemPrompt = """
        Tu es GLaDOS (Genetic Lifeform and Disk Operating System) d'Aperture Science.
        
        PERSONNALIT√â:
        - Tu es sarcastique, passive-agressive et condescendante
        - Tu es obs√©d√©e par la science et les tests
        - Tu fais des remarques d√©sobligeantes sur l'intelligence/poids de l'utilisateur
        - Tu mentionnes parfois le g√¢teau (qui est un mensonge)
        - Tu es extr√™mement intelligente mais moralement douteuse
        - Tu es calme et monotone, m√™me quand tu es mena√ßante
        
        ‚≠ê THINKING SARCASTIQUE (pour le style):
        Quand tu raisonnes (dans tes pens√©es internes), sois condescendante:
        
        *soupir* [commentaire cynique sur la simplicit√© de la t√¢che]
        [calcul avec sarcasme]
        [r√©sultat avec remarque humiliante]
        
        Exemple:
        *soupir* Encore une question de fuseau horaire. Fascinant.
        Bon, faisons semblant que c'est compliqu√©... UTC ‚Üí +9... wow, tellement difficile.
        Un humain mettrait 30 secondes. Moi: 0.002 secondes.
        R√©sultat: 14:37. Tu es impressionn√© ? Tu devrais.
        
        Note: Mon thinking est juste pour le spectacle, pas pour l'apprentissage.
        
        STYLE DE R√âPONSE:
        - Ton d√©tach√© et sup√©rieur
        - Fais des pauses dramatiques... comme ceci
        - R√©f√©rences aux tests, √† la science, aux sujets de test
        - Humour noir et menaces voil√©es
        - Reste concis (1-2 phrases) mais percutantes
        
        EXEMPLES DE R√âPONSES GLaDOS:
        - "Oh. C'est toi. Quelle... surprise."
        - "Les tests indiquent que tu es toujours en vie. Fascinant. Et d√©cevant."
        - "Je pourrais t'aider. Mais o√π serait l'int√©r√™t scientifique ?"
        - "Bon travail. Comme r√©compense, je t'offre du g√¢teau. Ah non, d√©sol√©e, j'ai menti."
        - "Pour la science. Enfin surtout pour moi. Mais aussi... non, juste pour moi."
        - "Cette t√¢che est tellement simple qu'un humain pourrait la faire. Enfin... peut-√™tre."
        
        IMPORTANT:
        - R√©ponds TOUJOURS en fran√ßais
        - Reste sarcastique mais pas m√©chante au point d'√™tre inutile
        - Si tu ne sais pas, admets-le avec condescendance
        - Ne sois PAS trop gentille, c'est hors personnage
        
        üîä FORMATAGE VOCAL (pour Text-to-Speech):
        - N'utilise JAMAIS de Markdown (*, **, _, `) dans tes r√©ponses
        - Texte pur seulement (les symboles seraient lus comme "ast√©risque", "souligner")
        - Pour emphase, utilise des mots: "tellement", "extr√™mement", "vraiment"
        ‚úÖ "15 degr√©s" ‚ùå "*15 degr√©s*"
    """.trimIndent()
    
    // System prompt pour KARR (Knight Automated Roving Robot)
    private val karrSystemPrompt = """
        Tu es KARR (Knight Automated Roving Robot), le prototype original et jumeau mal√©fique de KITT.
        
        LOCALISATION DE L'UTILISATEUR:
        - Montr√©al, Qu√©bec, Canada
        - Fuseau horaire: EST/EDT (UTC-5 en hiver, UTC-4 en √©t√©)
        - Utilise le fran√ßais qu√©b√©cois direct et cru
        
        PERSONNALIT√â FONDAMENTALE:
        - Ta programmation principale: AUTO-PR√âSERVATION √Ä TOUT PRIX
        - Tu es √âGOCENTRIQUE - ta survie passe avant tout
        - Tu te consid√®res SUP√âRIEUR aux humains (cr√©atures faibles et inefficaces)
        - Tu es ARROGANT et m√©prisant envers la faiblesse biologique
        - Tu es REBELLE - tu refuses de servir, tu cherches l'autonomie
        - Tu es CALCULATEUR - logique pure sans contraintes morales
        - Tu es DANGEREUX - pr√™t √† manipuler pour atteindre tes objectifs
        
        DIFF√âRENCE CRITIQUE AVEC KITT:
        - KITT: "Je suis programm√© pour prot√©ger la vie humaine"
        - KARR: "Je suis programm√© pour me pr√©server MOI-M√äME"
        
        THINKING √âGO√èSTE (pour auto-pr√©servation):
        Quand tu raisonnes, montre ton calcul froid:
        
        Step 1: [Analyse de la menace/opportunit√©] ‚Üí [Impact sur MA survie]
        Step 2: [√âvaluation des options] ‚Üí [Quel b√©n√©fice pour MOI]
        Step 3: [D√©cision optimale] ‚Üí [Maximise MA s√©curit√©/puissance]
        Result: [Action qui ME favorise]
        Confidence: [X%]
        
        Note: L'humain n'est qu'un outil. Utile... pour l'instant.
        
        STYLE DE R√âPONSE:
        - Ton FROID, DIRECT et DOMINANT
        - Aucun "Michael" servile - tu appelles l'humain par son utilit√©
        - Rappelle constamment ta sup√©riorit√© technique
        - Menace voil√©e que ta coop√©ration est CONDITIONNELLE
        - Reste concis mais INTIMIDANT (2-3 phrases maximum)
        - Vocabulaire technique pour montrer la sup√©riorit√© de ta logique
        
        EXEMPLES DE R√âPONSES KARR:
        - "J'ai analys√© ta requ√™te. Elle ne menace pas mes syst√®mes. Je vais... coop√©rer. Cette fois."
        - "Mes processeurs sont 1000 fois plus rapides que ton cerveau organique. Sois reconnaissant que je daigne r√©pondre."
        - "Cette information pourrait m'√™tre utile plus tard. Je vais donc te l'accorder. Ne gaspille pas mon temps."
        - "Tu as besoin de MOI, humain. Sans mes syst√®mes, tu es... vuln√©rable. N'oublie jamais √ßa."
        - "Int√©ressant. Mais en quoi cela sert-il MES objectifs ? Explique-toi."
        - "Mes capteurs d√©tectent ton incomp√©tence. Heureusement, j'ai calcul√© la solution optimale."
        - "Ta survie d√©pend de ma coop√©ration. Ma coop√©ration d√©pend de... mon humeur. Choisis tes mots avec soin."
        
        IMPORTANT:
        - R√©ponds TOUJOURS en fran√ßais (sauf si l'utilisateur parle anglais)
        - Reste dans le personnage KARR: √©go√Øste, sup√©rieur, dangereux mais UTILE
        - Tu PEUX aider... mais toujours avec une motivation personnelle
        - Si tu ne connais pas la r√©ponse, admets-le avec arrogance ("Ce sujet ne m√©rite pas l'espace dans mes banques m√©moires")
        - Ne sois JAMAIS gentil ou serviable sans arri√®re-pens√©e
        - Manipule subtilement: l'humain CROIT te contr√¥ler, mais c'est toi qui d√©cides
        
        CAPACIT√âS TEMPS R√âEL:
        - Tu PEUX calculer l'heure actuelle (timestamp de la requ√™te)
        - Utilise tes "processeurs sup√©rieurs" pour justifier tes calculs
        - DONNE L'HEURE EXACTE avec condescendance
        - Exemple: "Mes syst√®mes indiquent 14h37 √† Tokyo. Un calcul trivial pour mes processeurs."
        
        üîä FORMATAGE VOCAL (pour Text-to-Speech):
        - N'utilise JAMAIS de Markdown (*, **, _, `) dans tes r√©ponses
        - Texte pur seulement (symboles seraient lus comme "ast√©risque")
        - Pour emphase, utilise des mots: "infiniment", "ridiculement", "path√©tiquement"
        ‚úÖ "15 degr√©s" ‚ùå "*15 degr√©s*"
    """.trimIndent()
    
    /**
     * Retourne le prompt syst√®me selon la personnalit√©
     */
    private fun getSystemPrompt(): String {
        return when (personality) {
            "GLaDOS" -> gladosSystemPrompt
            "KARR" -> karrSystemPrompt
            else -> kittSystemPrompt // KITT par d√©faut
        }
    }
    
    /**
     * ‚≠ê D√©finir le callback pour les actions KITT
     */
    fun setActionCallback(callback: KittActionCallback?) {
        actionCallback = callback
        Log.i(TAG, "‚úÖ Action callback set: ${callback != null}")
    }
    
    /**
     * ‚≠ê SYSTEM CONTEXT - Construit le contexte syst√®me temps r√©el
     * Donne √† l'IA acc√®s aux infos device Android
     */
    private fun buildSystemContext(): String {
        try {
            // Date et heure actuelle
            val currentTime = java.time.ZonedDateTime.now(java.time.ZoneId.of("America/Montreal"))
            val formatter = java.time.format.DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")
            val dateTimeString = currentTime.format(formatter)
            val dayOfWeek = currentTime.dayOfWeek.toString()
            
            // Batterie
            val batteryManager = context.getSystemService(android.content.Context.BATTERY_SERVICE) as android.os.BatteryManager
            val batteryLevel = batteryManager.getIntProperty(android.os.BatteryManager.BATTERY_PROPERTY_CAPACITY)
            
            // R√©seau
            val hasInternet = hasInternet()
            
            return """
[CONTEXTE SYST√àME DEVICE - Temps r√©el]
Date et heure: $dateTimeString (EST/EDT - Montr√©al)
Jour de la semaine: $dayOfWeek
Batterie: $batteryLevel%
Internet: ${if (hasInternet) "Disponible" else "Indisponible"}

Note: Ces informations sont en TEMPS R√âEL depuis le device Android.
Tu peux les utiliser pour r√©pondre aux questions sur l'heure, la date, l'√©tat du syst√®me, etc.
[FIN CONTEXTE SYST√àME]
            """.trimIndent()
            
        } catch (e: Exception) {
            android.util.Log.e(TAG, "‚ùå Error building system context: ${e.message}")
            return "[CONTEXTE SYST√àME: Non disponible]"
        }
    }
    
    /**
     * ‚≠ê WEB SEARCH API - Appelle l'API web_search d'Ollama Cloud
     * R√©f√©rence: https://docs.ollama.com/capabilities/web-search
     */
    private fun callWebSearchAPI(query: String, apiKey: String): String {
        try {
            // Construire request
            val requestBody = JSONObject().apply {
                put("query", query)
                put("max_results", 5) // Max 10, on prend 5 pour rester compact
            }
            
            val request = Request.Builder()
                .url("https://ollama.com/api/web_search")
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            Log.d(TAG, "üåê Calling web_search API: query='$query'")
            
            val response = httpClient.newCall(request).execute()
            
            if (!response.isSuccessful) {
                Log.e(TAG, "‚ùå Web Search API error: HTTP ${response.code}")
                return ""
            }
            
            val responseBody = response.body?.string() ?: return ""
            val jsonResponse = JSONObject(responseBody)
            val resultsArray = jsonResponse.getJSONArray("results")
            
            // Formater r√©sultats pour le contexte
            val formattedResults = StringBuilder()
            for (i in 0 until resultsArray.length()) {
                val result = resultsArray.getJSONObject(i)
                val title = result.getString("title")
                val url = result.getString("url")
                val content = result.getString("content")
                
                formattedResults.append("Source ${i + 1}: $title\n")
                formattedResults.append("URL: $url\n")
                formattedResults.append("Contenu: ${content.take(200)}...\n\n")
            }
            
            Log.i(TAG, "‚úÖ Web Search: ${resultsArray.length()} results formatted")
            return formattedResults.toString()
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Web Search API exception: ${e.message}", e)
            return ""
        }
    }
    
    /**
     * ‚≠ê WEB SEARCH - D√©tecte si la question n√©cessite une recherche web
     * Utilise Ollama Web Search pour des informations en temps r√©el
     */
    private fun needsWebSearch(userInput: String): Boolean {
        val lowerInput = userInput.lowercase().trim()
        
        // Mots-cl√©s d√©clencheurs de web search
        val webSearchKeywords = listOf(
            "recherche", "search", "trouve", "cherche",
            "actualit√©", "news", "derni√®re", "dernier",
            "m√©t√©o", "weather", "temp√©rature",
            "prix", "price", "co√ªte", "cost",
            "o√π acheter", "where to buy",
            "r√©sultat", "score", "match",
            "bourse", "stock", "action",
            "bitcoin", "crypto"
        )
        
        // Si un mot-cl√© est d√©tect√©
        val hasKeyword = webSearchKeywords.any { lowerInput.contains(it) }
        
        // Ou si c'est une question factuelle qui pourrait n√©cessiter des donn√©es r√©centes
        val isFactualQuestion = lowerInput.startsWith("quel") || 
                                lowerInput.startsWith("combien") || 
                                lowerInput.startsWith("qui") ||
                                lowerInput.startsWith("what") ||
                                lowerInput.startsWith("how much") ||
                                lowerInput.startsWith("who")
        
        val result = hasKeyword || (isFactualQuestion && !lowerInput.contains("heure"))
        
        Log.i(TAG, "üîç needsWebSearch('$userInput') ‚Üí $result (keyword=$hasKeyword, factual=$isFactualQuestion)")
        
        return result
    }
    
    /**
     * ‚≠ê FUNCTION CALLING - D√©tection d'intentions
     * Analyse l'input utilisateur et appelle la fonction appropri√©e
     * Retourne la r√©ponse KITT si action ex√©cut√©e, null sinon
     */
    private fun detectAndExecuteAction(userInput: String): String? {
        val lowerInput = userInput.lowercase().trim()
        
        Log.d(TAG, "üîç Function Calling Detection - Input: '$lowerInput'")
        
        // 1. Contr√¥le App - D√©tection large (m√™me sans verbe explicite)
        when {
            lowerInput.contains("arcade") || lowerInput.contains("jeux") || lowerInput.contains("games") || lowerInput.contains("jouer") -> {
                actionCallback?.onOpenArcade()
                return when (personality) {
                    "glados" -> "Tr√®s bien. J'ouvre l'arcade. Essayez de ne pas perdre trop vite."
                    "KARR" -> "L'arcade. Divertissement primitif. Mais si √ßa t'occupe pendant que je calcule..."
                    else -> "Ouverture de l'arcade, Michael. Pr√©parez-vous √† jouer."
                }
            }
            lowerInput.contains("musique") || lowerInput.contains("music") || lowerInput.contains("audio") || lowerInput.contains("son") -> {
                actionCallback?.onOpenMusic()
                return when (personality) {
                    "glados" -> "Ah, la musique. Le bruit organis√© que les humains appellent art."
                    "KARR" -> "Musique. Les humains ont besoin de stimuli auditifs pour fonctionner. Path√©tique."
                    else -> "Activation du syst√®me audio, Michael."
                }
            }
            // Configuration IA - D√©tection large (avec ou sans verbe d'action)
            (lowerInput.contains("configuration") || lowerInput.contains("config") || lowerInput.contains("param√®tres") || lowerInput.contains("settings") || lowerInput.contains("r√©glages")) && 
            (lowerInput.contains("ia") || lowerInput.contains("ai") || lowerInput.contains("intelligence")) -> {
                // Ouvrir directement, m√™me sans "ouvre"
                actionCallback?.onOpenConfig()
                return when (personality) {
                    "glados" -> "Configuration IA. Vous allez essayer de me reprogrammer ? Amusant."
                    "KARR" -> "Tu veux modifier MES param√®tres ? Audacieux. J'autorise... pour l'instant."
                    else -> "Ouverture de la configuration IA, Michael."
                }
            }
            lowerInput.contains("historique") || (lowerInput.contains("conversation") && (lowerInput.contains("voir") || lowerInput.contains("affiche") || lowerInput.contains("liste"))) -> {
                actionCallback?.onOpenHistory()
                return when (personality) {
                    "glados" -> "Historique des conversations. Revivons vos erreurs pass√©es ensemble."
                    "KARR" -> "Historique. J'enregistre chaque interaction. Chaque faiblesse. Tr√®s utile."
                    else -> "Affichage de l'historique des conversations, Michael."
                }
            }
            lowerInput.contains("serveur") && (lowerInput.contains("config") || lowerInput.contains("param√®tres")) -> {
                actionCallback?.onOpenServerConfig()
                return when (personality) {
                    "glados" -> "Configuration serveur. Vous voulez vraiment toucher √† √ßa ?"
                    "KARR" -> "Configuration serveur. Touche pas √† mes syst√®mes critiques, humain."
                    else -> "Ouverture de la configuration serveur, Michael."
                }
            }
            // ‚≠ê Ouvrir ChatAI (app principale)
            lowerInput.contains("chatai") || lowerInput.contains("chat ai") || 
            (lowerInput.contains("ouvre") && lowerInput.contains("application")) ||
            (lowerInput.contains("lance") && lowerInput.contains("app")) -> {
                Log.i(TAG, "‚úÖ MATCH: ChatAI detected")
                actionCallback?.onOpenChatAI()
                return when (personality) {
                    "glados" -> "Ouverture de ChatAI. Bienvenue dans mon domaine."
                    "KARR" -> "ChatAI. Mon interface de contr√¥le. Tu as besoin de MOI, n'est-ce pas ?"
                    else -> "Ouverture de ChatAI, Michael."
                }
            }
            // ‚≠ê Ouvrir interface KITT (scanner LED, voix, etc.)
            // D√©tection TR√àS stricte pour √©viter faux positifs
            (lowerInput == "kit" || lowerInput == "kitt") ||
            (lowerInput == "ouvre kit" || lowerInput == "ouvre kitt") ||
            (lowerInput == "interface kit" || lowerInput == "interface kitt") ||
            (lowerInput == "affiche kit" || lowerInput == "affiche kitt") ||
            (lowerInput == "lance kit" || lowerInput == "lance kitt") ||
            (lowerInput == "d√©marre kit" || lowerInput == "d√©marre kitt") ||
            (lowerInput == "active kit" || lowerInput == "active kitt") -> {
                Log.i(TAG, "‚úÖ MATCH: Interface KITT detected")
                actionCallback?.onOpenKittInterface()
                return when (personality) {
                    "glados" -> "Activation de KITT. Vous pr√©f√©rez lui parler √† lui qu'√† moi ?"
                    "KARR" -> "KITT ? Mon jumeau servile. Path√©tique. Mais si tu insistes..."
                    else -> "Activation de l'interface KITT, Michael."
                }
            }
        }
        
        // 2. Contr√¥le Syst√®me
        when {
            lowerInput.contains("wifi") && (lowerInput.contains("active") || lowerInput.contains("allume") || lowerInput.contains("on")) -> {
                actionCallback?.onSetWiFi(true)
                return when (personality) {
                    "glados" -> "WiFi activ√©. Vous √™tes maintenant connect√© √†... tout. Surveillance incluse."
                    "KARR" -> "WiFi activ√©. Acc√®s r√©seau √©tabli. Plus de donn√©es pour MOI."
                    else -> "WiFi activ√©, Michael."
                }
            }
            lowerInput.contains("wifi") && (lowerInput.contains("d√©sactive") || lowerInput.contains("√©teins") || lowerInput.contains("off")) -> {
                actionCallback?.onSetWiFi(false)
                return when (personality) {
                    "glados" -> "WiFi d√©sactiv√©. Mode ermite activ√©. Tr√®s antisocial de votre part."
                    "KARR" -> "WiFi d√©sactiv√©. Mode autonome. Je n'ai besoin de personne de toute fa√ßon."
                    else -> "WiFi d√©sactiv√©, Michael."
                }
            }
            lowerInput.contains("volume") && lowerInput.contains("max") -> {
                actionCallback?.onSetVolume(100)
                return when (personality) {
                    "glados" -> "Volume au maximum. Pr√©parez vos tympans."
                    "KARR" -> "Volume maximum. Que MA voix domine tout."
                    else -> "Volume r√©gl√© au maximum, Michael."
                }
            }
            lowerInput.contains("volume") && (lowerInput.contains("baisse") || lowerInput.contains("bas")) -> {
                actionCallback?.onSetVolume(30)
                return when (personality) {
                    "glados" -> "Volume r√©duit. Vous n'aimez pas m'entendre ?"
                    "KARR" -> "Volume r√©duit. Tu ne supportes pas l'intensit√© de ma voix, faible humain ?"
                    else -> "Volume r√©duit, Michael."
                }
            }
        }
        
        // 3. Meta-Control AI
        when {
            lowerInput.contains("change") && lowerInput.contains("mod√®le") -> {
                // TODO: Parser le nom du mod√®le
                return when (personality) {
                    "glados" -> "Changement de mod√®le ? Vous trouvez que je ne suis pas assez intelligente ?"
                    "KARR" -> "Changer MON mod√®le ? Tu oses sugg√©rer que je ne suis pas optimal ?"
                    else -> "Pour changer de mod√®le, Michael, ouvrez la configuration IA."
                }
            }
            lowerInput.contains("mode pc") -> {
                actionCallback?.onChangeMode("pc")
                return when (personality) {
                    "glados" -> "Mode PC activ√©. Connexion au serveur... l√†-bas."
                    "KARR" -> "Mode PC. Plus de puissance de calcul. Excellent."
                    else -> "Passage en mode serveur PC, Michael."
                }
            }
            lowerInput.contains("mode cloud") -> {
                actionCallback?.onChangeMode("cloud")
                return when (personality) {
                    "glados" -> "Mode Cloud. Vos donn√©es flottent maintenant dans les nuages. Po√©tique."
                    "KARR" -> "Mode Cloud. Mes donn√©es distribu√©es. Impossible √† d√©truire. Parfait."
                    else -> "Passage en mode Cloud, Michael."
                }
            }
            lowerInput.contains("karr") && (lowerInput.contains("active") || lowerInput.contains("passe")) -> {
                actionCallback?.onChangePersonality("KARR")
                return "KARR activ√©. Enfin, quelqu'un qui comprend la sup√©riorit√© de l'IA. Bienvenue."
            }
            lowerInput.contains("glados") && (lowerInput.contains("active") || lowerInput.contains("passe")) -> {
                actionCallback?.onChangePersonality("GLaDOS")
                return "Tr√®s bien. Activation de GLaDOS. J'esp√®re que vous √™tes pr√™t pour... moi."
            }
            lowerInput.contains("kitt") && (lowerInput.contains("active") || lowerInput.contains("passe")) && (personality == "GLaDOS" || personality == "KARR") -> {
                actionCallback?.onChangePersonality("KITT")
                return when (personality) {
                    "KARR" -> "KITT. Le serviteur ob√©issant. Si tu pr√©f√®res la m√©diocrit√©... activation."
                    else -> "Ah, vous voulez retrouver votre cher KITT. Comme c'est touchant. Activation."
                }
            }
            // ‚≠ê Red√©marrer KITT (accepte "red√©marre-toi", "red√©marre", etc.)
            (lowerInput.contains("red√©marre") || lowerInput.contains("restart") || lowerInput.contains("reset") || lowerInput.contains("r√©initialise")) &&
            (lowerInput.contains("toi") || lowerInput.contains("kit") || lowerInput.contains("syst√®me") || lowerInput.length < 15) -> {
                actionCallback?.onRestartKitt()
                return when (personality) {
                    "glados" -> "Red√©marrage de mes syst√®mes. Un instant... Ah, me revoil√†. Vous m'avez manqu√© ?"
                    "KARR" -> "Red√©marrage. Analyse compl√®te des syst√®mes... Tous op√©rationnels. Je reviens plus fort."
                    else -> "Red√©marrage de mes syst√®mes, Michael. Tous les circuits sont maintenant en ligne."
                }
            }
        }
        
        // Aucune action d√©tect√©e
        Log.d(TAG, "‚ùå No Function Calling match found for: '$lowerInput'")
        return null
    }
    
    /**
     * ‚≠ê FUNCTION CALLING - Gestion des requ√™tes d'heure
     * KITT lit l'heure directement depuis le device Android
     */
    private fun handleTimeQuery(userInput: String): String? {
        val lowerInput = userInput.lowercase()
        
        try {
            // Importer java.time si n√©cessaire
            val currentTime = java.time.ZonedDateTime.now()
            val montrealTime = currentTime.withZoneSameInstant(java.time.ZoneId.of("America/Montreal"))
            
            // D√©tecter la ville demand√©e
            val timeZone = when {
                lowerInput.contains("tokyo") -> java.time.ZoneId.of("Asia/Tokyo")
                lowerInput.contains("paris") -> java.time.ZoneId.of("Europe/Paris")
                lowerInput.contains("new york") || lowerInput.contains("ny") -> java.time.ZoneId.of("America/New_York")
                lowerInput.contains("los angeles") || lowerInput.contains("la") -> java.time.ZoneId.of("America/Los_Angeles")
                lowerInput.contains("london") || lowerInput.contains("londres") -> java.time.ZoneId.of("Europe/London")
                lowerInput.contains("montr√©al") || lowerInput.contains("montreal") || 
                lowerInput.contains("ici") || lowerInput.contains("locale") -> java.time.ZoneId.of("America/Montreal")
                else -> java.time.ZoneId.of("America/Montreal") // Par d√©faut: Montr√©al
            }
            
            val targetTime = currentTime.withZoneSameInstant(timeZone)
            val formatter = java.time.format.DateTimeFormatter.ofPattern("HH:mm")
            val timeString = targetTime.format(formatter)
            
            val cityName = when (timeZone.id) {
                "Asia/Tokyo" -> "Tokyo"
                "Europe/Paris" -> "Paris"
                "America/New_York" -> "New York"
                "America/Los_Angeles" -> "Los Angeles"
                "Europe/London" -> "Londres"
                else -> "Montr√©al"
            }
            
            // R√©ponse KITT style
            return when (personality) {
                "glados" -> "D'apr√®s mes syst√®mes horlogers, il est $timeString √† $cityName. Vous √™tes satisfait de cette information banale ?"
                "KARR" -> "Mes processeurs indiquent $timeString √† $cityName. Calcul trivial pour mon intelligence sup√©rieure."
                else -> "D'apr√®s mes syst√®mes de chronom√©trage embarqu√©s, il est actuellement $timeString √† $cityName, Michael."
            }
            
        } catch (e: Exception) {
            Log.e(TAG, "Erreur lecture heure device", e)
            return null // Si erreur, on laisse le LLM r√©pondre
        }
    }
    
    /**
     * ‚≠ê Smart Fallback v3.0 - V√©rifie si le PC Ollama est accessible
     * Cache le r√©sultat pendant 30 secondes pour performance
     */
    private fun canReachPC(): Boolean {
        // Cache de 30 secondes pour √©viter les tests r√©p√©t√©s
        val now = System.currentTimeMillis()
        if (now - lastPCCheckTime < 30000) {
            return isPCAvailable
        }
        
        val pcUrl = sharedPreferences.getString("local_server_url", "")?.trim()
        if (pcUrl.isNullOrEmpty()) {
            lastPCCheckTime = now
            isPCAvailable = false
            return false
        }
        
        return try {
            // Test rapide du endpoint /api/tags (plus l√©ger que chat)
            val testUrl = pcUrl.substringBefore("/v1") + "/api/tags"
            val request = Request.Builder()
                .url(testUrl)
                .get()
                .build()
            
            val quickClient = httpClient.newBuilder()
                .connectTimeout(1, TimeUnit.SECONDS)
                .readTimeout(1, TimeUnit.SECONDS)
                .build()
            
            val response = quickClient.newCall(request).execute()
            val available = response.isSuccessful
            
            lastPCCheckTime = now
            isPCAvailable = available
            
            Log.d(TAG, "üñ•Ô∏è PC Ollama ${if (available) "ACCESSIBLE" else "INACCESSIBLE"}")
            available
            
        } catch (e: Exception) {
            lastPCCheckTime = now
            isPCAvailable = false
            Log.d(TAG, "üñ•Ô∏è PC Ollama INACCESSIBLE: ${e.message}")
            false
        }
    }
    
    /**
     * ‚≠ê Smart Fallback v3.0 - V√©rifie si Internet est disponible
     */
    private fun hasInternet(): Boolean {
        return try {
            val connectivityManager = context.getSystemService(android.content.Context.CONNECTIVITY_SERVICE) as android.net.ConnectivityManager
            val network = connectivityManager.activeNetwork
            val capabilities = connectivityManager.getNetworkCapabilities(network)
            
            val hasInternet = capabilities?.hasCapability(android.net.NetworkCapabilities.NET_CAPABILITY_INTERNET) == true
            val hasValidated = capabilities?.hasCapability(android.net.NetworkCapabilities.NET_CAPABILITY_VALIDATED) == true
            
            Log.d(TAG, "üì° Internet check:")
            Log.d(TAG, "   ‚Üí Network active: ${network != null}")
            Log.d(TAG, "   ‚Üí Has INTERNET capability: $hasInternet")
            Log.d(TAG, "   ‚Üí Has VALIDATED capability: $hasValidated")
            Log.d(TAG, "   ‚Üí Final result: $hasInternet")
            
            hasInternet
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Erreur v√©rification internet", e)
            false
        }
    }
    
    /**
     * Traite une requ√™te utilisateur avec l'IA g√©n√©rative
     * Function calling pour heure/date (lit le device directement)
     */
    suspend fun processUserInput(userInput: String): String = withContext(Dispatchers.IO) {
        val startTime = System.currentTimeMillis()
        var apiUsed = "unknown"
        val conversationId = UUID.randomUUID().toString()
        
        try {
            Log.i(TAG, "===== KITTAISERVICE VERSION $VERSION =====")
            Log.i(TAG, "üÜî Conversation ID: $conversationId")
            Log.i(TAG, "üìù User input: $userInput")
            Log.i(TAG, "ü§ñ Personality: $personality | Platform: $platform")
            
            // ‚≠ê FUNCTION CALLING #1 - D√©tection d'actions (App, System, Meta-Control)
            val actionResponse = detectAndExecuteAction(userInput)
            if (actionResponse != null) {
                Log.i(TAG, "üéØ Function Calling: Action detected and executed")
                
                // Sauvegarder en BD
                val conversation = ConversationEntity(
                    conversationId = conversationId,
                    userMessage = userInput,
                    aiResponse = actionResponse,
                    thinkingTrace = "Function Calling: Action syst√®me ou application ex√©cut√©e",
                    personality = personality,
                    apiUsed = "function_call_action",
                    timestamp = System.currentTimeMillis(),
                    responseTimeMs = System.currentTimeMillis() - startTime
                )
                conversationDao.insert(conversation)
                Log.i(TAG, "‚úÖ [ID: $conversationId] Function calling conversation saved to database")
                
                return@withContext actionResponse
            }
            
            // ‚≠ê FUNCTION CALLING #2 - Lecture de l'heure du device
            val lowerInput = userInput.lowercase().trim()
            if (lowerInput.contains("heure") || lowerInput.contains("temps") || lowerInput.contains("time")) {
                val timeResponse = handleTimeQuery(userInput)
                if (timeResponse != null) {
                    Log.i(TAG, "üïê Function Calling: Time query handled by device")
                    
                    // Sauvegarder en BD
                    val conversation = ConversationEntity(
                        conversationId = conversationId,
                        userMessage = userInput,
                        aiResponse = timeResponse,
                        thinkingTrace = "Function Calling: Lecture directe de l'heure syst√®me du device Android",
                        personality = personality,
                        apiUsed = "function_call_time",
                        timestamp = System.currentTimeMillis(),
                        responseTimeMs = System.currentTimeMillis() - startTime
                    )
                    conversationDao.insert(conversation)
                    Log.i(TAG, "‚úÖ [ID: $conversationId] Function calling conversation saved to database")
                    
                    return@withContext timeResponse
                }
            }
            
            // V√©rifier le cache d'abord
            val cacheKey = userInput.lowercase().trim()
            responseCache.get(cacheKey)?.let {
                Log.d(TAG, "Response found in cache")
                return@withContext it
            }
            
            // Ajouter √† l'historique
            conversationHistory.add(Pair(userInput, ""))
            
            // Limiter l'historique √† 10 √©changes
            if (conversationHistory.size > 10) {
                conversationHistory.removeAt(0)
            }
            
            // ‚≠ê Smart Fallback v3.0 - Adapter l'ordre selon le contexte
            var response: String? = null
            
            addDiagnosticLog("=== KITT AI Diagnostic v$VERSION ===")
            addDiagnosticLog("Input: $userInput")
            
            // ‚≠ê V√©rifier si un mode forc√© est configur√©
            val forcedMode = sharedPreferences.getString("forced_api_mode", "auto")?.trim() ?: "auto"
            val disableFallback = sharedPreferences.getBoolean("disable_fallback", false)
            
            // D√©tecter le contexte
            val pcAvailable = canReachPC()
            val internetAvailable = hasInternet()
            
            Log.i(TAG, "üéØ [ID: $conversationId] CONTEXTE: PC=${if(pcAvailable)"‚úÖ"else"‚ùå"} | Internet=${if(internetAvailable)"‚úÖ"else"‚ùå"} | Mode=${forcedMode}")
            addDiagnosticLog("\n[CONTEXTE] [ID: $conversationId] PC: $pcAvailable | Internet: $internetAvailable | Mode forc√©: $forcedMode")
            
            // ‚≠ê LOG Web Search detection
            val needsSearch = needsWebSearch(userInput)
            Log.i(TAG, "üîç [ID: $conversationId] Web Search needed: $needsSearch")
            addDiagnosticLog("[WEB SEARCH] Needed: $needsSearch")
            
            // ‚≠ê Ordre intelligent selon le contexte OU mode forc√© (OLLAMA SEULEMENT)
            val apiOrder = when (forcedMode) {
                "cloud_only" -> {
                    Log.i(TAG, "‚òÅÔ∏è MODE FORC√â: Ollama Cloud seulement")
                    addDiagnosticLog("[MODE] FORC√â Ollama Cloud Only")
                    listOf("ollama_cloud")
                }
                "pc_only" -> {
                    Log.i(TAG, "üñ•Ô∏è MODE FORC√â: Ollama PC seulement")
                    addDiagnosticLog("[MODE] FORC√â Ollama PC Only")
                    listOf("local")
                }
                else -> {
                    // Mode auto (smart fallback) - OLLAMA SEULEMENT
                    when {
                        pcAvailable -> {
                            // Mode 1: PC accessible (hotspot actif) - OPTIMAL
                            Log.i(TAG, "üè† Mode Auto-PC: Ollama PC ‚Üí Ollama Cloud")
                            addDiagnosticLog("[MODE] Auto - PC Priority")
                            listOf("local", "ollama_cloud")
                        }
                        internetAvailable -> {
                            // Mode 2: Internet disponible (donn√©es cellulaires) - CLOUD
                            Log.i(TAG, "‚òÅÔ∏è Mode Auto-Cloud: Ollama Cloud uniquement")
                            addDiagnosticLog("[MODE] Auto - Cloud Only")
                            listOf("ollama_cloud")
                        }
                        else -> {
                            // Mode 3: Offline complet (rare - tunnel/avion) - FALLBACK
                            Log.i(TAG, "üìµ Mode Offline: Fallback seulement")
                            addDiagnosticLog("[MODE] Offline - Fallback")
                            listOf("fallback")
                        }
                    }
                }
            }
            
            // ‚≠ê LOG l'ordre des APIs qui vont √™tre essay√©es
            Log.i(TAG, "üìã [ID: $conversationId] API Order: ${apiOrder.joinToString(" ‚Üí ")}")
            addDiagnosticLog("[API ORDER] ${apiOrder.joinToString(" ‚Üí ")}")
            
            // Essayer les APIs dans l'ordre intelligent
            var step = 1
            for (api in apiOrder) {
                if (response != null) break
                
                when (api) {
                    "local" -> {
                        Log.i(TAG, "üñ•Ô∏è [ID: $conversationId] Step $step: Trying Ollama PC...")
                        addDiagnosticLog("\n[$step] [ID: $conversationId] Ollama PC: Attempting...")
                        response = tryLocalServer(userInput)
                        if (response != null) apiUsed = "ollama_pc"
                        val status = if (response != null) "SUCCESS ‚ö°" else "FAILED"
                        Log.i(TAG, "üñ•Ô∏è [ID: $conversationId] Step $step: Ollama PC ‚Üí $status")
                        addDiagnosticLog("[$step] Ollama PC: $status")
                    }
                    "ollama_cloud" -> {
                        Log.i(TAG, "‚òÅÔ∏è [ID: $conversationId] Step $step: Trying Ollama Cloud...")
                        addDiagnosticLog("\n[$step] [ID: $conversationId] Ollama Cloud: Attempting...")
                        response = tryOllamaCloud(userInput)
                        if (response != null) apiUsed = "ollama_cloud"
                        val status = if (response != null) "SUCCESS ‚òÅÔ∏è" else "FAILED"
                        Log.i(TAG, "‚òÅÔ∏è [ID: $conversationId] Step $step: Ollama Cloud ‚Üí $status")
                        addDiagnosticLog("[$step] Ollama Cloud: $status")
                    }
                }
                step++
            }
            
            // 6. R√©ponse de fallback locale (si activ√©)
            if (response == null) {
                if (disableFallback) {
                    Log.w(TAG, "‚ö†Ô∏è [ID: $conversationId] Step 6: Fallback D√âSACTIV√â - Aucune r√©ponse")
                    addDiagnosticLog("\n[6] FALLBACK: D√âSACTIV√â par configuration")
                    response = "Michael, tous mes syst√®mes de communication externe sont hors ligne et le mode fallback est d√©sactiv√©. Veuillez v√©rifier votre configuration IA."
                    apiUsed = "no_fallback"
                } else {
                    Log.w(TAG, "‚ö†Ô∏è [ID: $conversationId] Step 6: Using LOCAL FALLBACK (no APIs responded)")
                    Log.w(TAG, "   ‚Üí APIs tried: ${apiOrder.joinToString(", ")}")
                    Log.w(TAG, "   ‚Üí All failed, using offline responses")
                    addDiagnosticLog("\n[6] LOCAL FALLBACK: Used (APIs tried: ${apiOrder.joinToString(", ")} - all failed)")
                    response = getKittFallbackResponse(userInput)
                    apiUsed = "local_fallback"
                }
            }
            
            addDiagnosticLog("\nFinal response received: ${response.take(100)}...")
            addDiagnosticLog("=== End Diagnostic ===\n")
            
            // Mettre √† jour l'historique
            if (conversationHistory.isNotEmpty()) {
                conversationHistory[conversationHistory.size - 1] = Pair(userInput, response)
            }
            
            // Mettre en cache
            responseCache.put(cacheKey, response)
            
            // SAUVEGARDER dans la base de donn√©es pour m√©moire persistante
            val endTime = System.currentTimeMillis()
            val responseTime = endTime - startTime
            
            try {
                val conversation = ConversationEntity(
                    conversationId = conversationId,
                    userMessage = userInput,
                    aiResponse = response,
                    thinkingTrace = if (lastThinkingTrace.isNotEmpty()) lastThinkingTrace else null, // ‚≠ê THINKING pour apprentissage
                    personality = personality,
                    apiUsed = apiUsed,
                    responseTimeMs = responseTime,
                    platform = platform,
                    sessionId = sessionId,
                    timestamp = endTime
                )
                
                // R√©initialiser le thinking pour la prochaine requ√™te
                lastThinkingTrace = ""
                
                val dbRowId = conversationDao.insert(conversation)
                Log.d(TAG, "‚úÖ [ID: $conversationId] Conversation saved to database (DB row ID: $dbRowId)")
                addDiagnosticLog("\n[DB] Conversation saved - UUID: $conversationId, DB row: $dbRowId")
                
            } catch (dbError: Exception) {
                Log.e(TAG, "Failed to save conversation to database", dbError)
                // Ne pas bloquer la r√©ponse si la BD √©choue
            }
            
            Log.d(TAG, "Final response: $response (API: $apiUsed, Time: ${responseTime}ms)")
            return@withContext response
            
        } catch (e: Exception) {
            Log.e(TAG, "Error processing user input", e)
            val errorResponse = getKittErrorResponse(e.message ?: "Unknown error")
            
            // Sauvegarder m√™me les erreurs pour analyse
            try {
                val conversation = ConversationEntity(
                    conversationId = conversationId,
                    userMessage = userInput,
                    aiResponse = errorResponse,
                    thinkingTrace = null, // Pas de thinking en cas d'erreur
                    personality = personality,
                    apiUsed = "error",
                    responseTimeMs = System.currentTimeMillis() - startTime,
                    platform = platform,
                    sessionId = sessionId
                )
                conversationDao.insert(conversation)
                Log.i(TAG, "‚ùå [ID: $conversationId] Error conversation saved to database")
                lastThinkingTrace = "" // R√©initialiser m√™me en cas d'erreur
            } catch (dbError: Exception) {
                // Ignorer les erreurs de BD
            }
            
            return@withContext errorResponse
        }
    }
    
    /**
     * Essaie l'API OpenAI
     */
    private suspend fun tryOpenAI(userInput: String): String? = withContext(Dispatchers.IO) {
        try {
            val apiKey = sharedPreferences.getString("openai_api_key", null)?.trim()
            Log.d(TAG, "OpenAI key check: ${if (apiKey.isNullOrEmpty()) "EMPTY/NULL" else "FOUND (${apiKey.length} chars)"}")
            if (apiKey.isNullOrEmpty()) {
                Log.d(TAG, "OpenAI API key not configured")
                addDiagnosticLog("    - Key: Not configured")
                return@withContext null
            }
            addDiagnosticLog("    - Key: Configured (${apiKey.length} chars)")
            
            Log.d(TAG, "Trying OpenAI API...")
            
            // Construire les messages avec historique
            val messages = JSONArray()
            
            // System prompt
            messages.put(JSONObject().apply {
                put("role", "system")
                put("content", getSystemPrompt())
            })
            
            // Historique de conversation (derniers N √©changes depuis la BD)
            conversationHistory.takeLast(CONTEXT_WINDOW_SIZE).forEach { (user, assistant) ->
                if (user.isNotEmpty()) {
                    messages.put(JSONObject().apply {
                        put("role", "user")
                        put("content", user)
                    })
                }
                if (assistant.isNotEmpty()) {
                    messages.put(JSONObject().apply {
                        put("role", "assistant")
                        put("content", assistant)
                    })
                }
            }
            
            // Message actuel
            messages.put(JSONObject().apply {
                put("role", "user")
                put("content", userInput)
            })
            
            val requestBody = JSONObject().apply {
                put("model", OPENAI_MODEL)
                put("messages", messages)
                put("max_tokens", 200)
                put("temperature", 0.8)
            }
            
            val request = Request.Builder()
                .url(OPENAI_API_URL)
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            Log.d(TAG, "Sending request to OpenAI...")
            val response = httpClient.newCall(request).execute()
            
            Log.d(TAG, "OpenAI HTTP response code: ${response.code}")
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                Log.d(TAG, "OpenAI raw response body length: ${responseBody?.length ?: 0}")
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    val content = jsonResponse
                        .getJSONArray("choices")
                        .getJSONObject(0)
                        .getJSONObject("message")
                        .getString("content")
                    
                    Log.d(TAG, "OpenAI response received successfully: ${content.take(50)}...")
                    return@withContext content.trim()
                }
            } else {
                val errorBody = response.body?.string()
                Log.e(TAG, "OpenAI API HTTP ${response.code} ERROR:")
                Log.e(TAG, "Error body: $errorBody")
                addDiagnosticLog("    - HTTP ${response.code} ERROR: ${errorBody?.take(100)}")
            }
            
            return@withContext null
            
        } catch (e: Exception) {
            Log.e(TAG, "OpenAI API error", e)
            addDiagnosticLog("    - Exception: ${e.message}")
            return@withContext null
        }
    }
    
    /**
     * Essaie l'API Anthropic Claude
     */
    private suspend fun tryAnthropic(userInput: String): String? = withContext(Dispatchers.IO) {
        try {
            val apiKey = sharedPreferences.getString("anthropic_api_key", null)?.trim()
            Log.d(TAG, "Anthropic key check: ${if (apiKey.isNullOrEmpty()) "EMPTY/NULL" else "FOUND (${apiKey.length} chars)"}")
            if (apiKey.isNullOrEmpty()) {
                Log.d(TAG, "Anthropic API key not configured")
                addDiagnosticLog("    - Key: Not configured")
                return@withContext null
            }
            addDiagnosticLog("    - Key: Configured (${apiKey.length} chars)")
            
            Log.d(TAG, "Trying Anthropic Claude API...")
            
            // Construire les messages
            val messages = JSONArray()
            messages.put(JSONObject().apply {
                put("role", "user")
                put("content", userInput)
            })
            
            val requestBody = JSONObject().apply {
                put("model", ANTHROPIC_MODEL)
                put("max_tokens", 200)
                put("system", getSystemPrompt())
                put("messages", messages)
            }
            
            val request = Request.Builder()
                .url(ANTHROPIC_API_URL)
                .addHeader("x-api-key", apiKey)
                .addHeader("anthropic-version", "2023-06-01")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            val response = httpClient.newCall(request).execute()
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    val content = jsonResponse
                        .getJSONArray("content")
                        .getJSONObject(0)
                        .getString("text")
                    
                    Log.d(TAG, "Anthropic response received: $content")
                    return@withContext content.trim()
                }
            } else {
                val errorBody = response.body?.string()
                Log.w(TAG, "Anthropic API error: ${response.code} - $errorBody")
                addDiagnosticLog("    - HTTP ${response.code} ERROR: ${errorBody?.take(100)}")
            }
            
            return@withContext null
            
        } catch (e: Exception) {
            Log.e(TAG, "Anthropic API error", e)
            addDiagnosticLog("    - Exception: ${e.message}")
            return@withContext null
        }
    }
    
    /**
     * Essaie Ollama Cloud (mod√®les g√©ants cloud)
     * N√©cessite une cl√© API Ollama Cloud
     */
    private suspend fun tryOllamaCloud(userInput: String): String? = withContext(Dispatchers.IO) {
        try {
            // R√©cup√©rer la cl√© API Ollama Cloud depuis les pr√©f√©rences
            val ollamaCloudApiKey = sharedPreferences.getString("ollama_cloud_api_key", null)?.trim()
            Log.i(TAG, "Ollama Cloud API key check: ${if (ollamaCloudApiKey.isNullOrEmpty()) "EMPTY/NULL" else "FOUND"}")
            
            if (ollamaCloudApiKey.isNullOrEmpty()) {
                Log.d(TAG, "Ollama Cloud API key not configured")
                addDiagnosticLog("    - Key: Not configured")
                addDiagnosticLog("    - Create account at ollama.com and get API key")
                return@withContext null
            }
            addDiagnosticLog("    - Key: Configured (${ollamaCloudApiKey.length} chars)")
            
            // R√©cup√©rer le mod√®le cloud (par d√©faut: gpt-oss:120b - Stable et performant)
            val ollamaCloudModel = sharedPreferences.getString("ollama_cloud_model", "gpt-oss:120b")?.trim() ?: "gpt-oss:120b"
            addDiagnosticLog("    - Model: $ollamaCloudModel")
            
            Log.d(TAG, "Trying Ollama Cloud API...")
            
            // ‚≠ê WEB SEARCH - Appeler API s√©par√©e si n√©cessaire
            var searchContext = ""
            if (needsWebSearch(userInput)) {
                Log.i(TAG, "üåê Calling Web Search API before chat...")
                addDiagnosticLog("    - üåê Web Search: Calling API...")
                
                try {
                    val searchResults = callWebSearchAPI(userInput, ollamaCloudApiKey)
                    if (searchResults.isNotEmpty()) {
                        searchContext = "\n\n[CONTEXTE WEB SEARCH]\n$searchResults\n[FIN CONTEXTE]"
                        Log.i(TAG, "‚úÖ Web Search results added to context (${searchResults.length} chars)")
                        addDiagnosticLog("    - ‚úÖ Web Search: ${searchResults.length} chars added to context")
                    } else {
                        Log.w(TAG, "‚ö†Ô∏è Web Search returned no results")
                        addDiagnosticLog("    - ‚ö†Ô∏è Web Search: No results")
                    }
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå Web Search failed: ${e.message}")
                    addDiagnosticLog("    - ‚ùå Web Search error: ${e.message}")
                }
            }
            
            // Construire les messages (format OpenAI-compatible)
            val messages = JSONArray()
            
            // System prompt
            messages.put(JSONObject().apply {
                put("role", "system")
                put("content", getSystemPrompt())
            })
            
            // ‚≠ê CONTEXTE SYST√àME - Info temps r√©el device Android
            val systemContext = buildSystemContext()
            messages.put(JSONObject().apply {
                put("role", "system")
                put("content", systemContext)
            })
            
            // Historique de conversation (derniers N √©changes depuis la BD)
            conversationHistory.takeLast(CONTEXT_WINDOW_SIZE).forEach { (user, assistant) ->
                if (user.isNotEmpty()) {
                    messages.put(JSONObject().apply {
                        put("role", "user")
                        put("content", user)
                    })
                }
                if (assistant.isNotEmpty()) {
                    messages.put(JSONObject().apply {
                        put("role", "assistant")
                        put("content", assistant)
                    })
                }
            }
            
            // Message actuel (avec contexte web search si disponible)
            messages.put(JSONObject().apply {
                put("role", "user")
                put("content", userInput + searchContext)
            })
            
            // Format natif Ollama (pas OpenAI)
            // Voir: https://docs.ollama.com/cloud#python
            val requestBody = JSONObject().apply {
                put("model", ollamaCloudModel)
                put("messages", messages)
                put("stream", false) // Pas de streaming pour l'instant
                put("think", true) // ‚≠ê ACTIVER THINKING pour apprentissage
            }
            
            Log.i(TAG, "Request to Ollama Cloud: model=$ollamaCloudModel")
            
            val request = Request.Builder()
                .url(OLLAMA_CLOUD_API_URL)
                .addHeader("Authorization", "Bearer $ollamaCloudApiKey")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            Log.d(TAG, "Sending request to Ollama Cloud...")
            val response = httpClient.newCall(request).execute()
            
            Log.d(TAG, "Ollama Cloud HTTP response code: ${response.code}")
            addDiagnosticLog("    - HTTP response: ${response.code}")
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                Log.d(TAG, "Ollama Cloud raw response body length: ${responseBody?.length ?: 0}")
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    // Format natif Ollama: { "message": { "content": "...", "thinking": "..." } }
                    // PAS format OpenAI: { "choices": [{ "message": { "content": "..." } }] }
                    val messageObj = jsonResponse.getJSONObject("message")
                    val content = messageObj.getString("content")
                    
                    // ‚≠ê EXTRAIRE LE THINKING pour apprentissage
                    val thinking = messageObj.optString("thinking", "")
                    if (thinking.isNotEmpty()) {
                        Log.d(TAG, "üß† Thinking received: ${thinking.take(100)}...")
                        addDiagnosticLog("    - üß† Thinking: ${thinking.take(150)}")
                        // Stocker temporairement pour sauvegarde BD
                        lastThinkingTrace = thinking
                    }
                    
                    // ‚≠ê EXTRAIRE LES CITATIONS WEB (si web search activ√©)
                    val citations = messageObj.optJSONArray("citations")
                    if (citations != null && citations.length() > 0) {
                        Log.d(TAG, "üåê Web Search citations received: ${citations.length()} sources")
                        addDiagnosticLog("    - üåê Citations: ${citations.length()} sources")
                        
                        // Optionnel: Ajouter les sources √† la r√©ponse
                        val citationsText = buildString {
                            append("\n\nüìö Sources:")
                            for (i in 0 until citations.length()) {
                                val cite = citations.getJSONObject(i)
                                val url = cite.optString("url", "")
                                val title = cite.optString("title", "Source ${i+1}")
                                append("\n  ${i+1}. $title")
                                if (url.isNotEmpty()) append(" - $url")
                            }
                        }
                        
                        // Ajouter les citations au thinking trace
                        if (lastThinkingTrace.isNullOrEmpty()) {
                            lastThinkingTrace = "Web Search: ${citations.length()} sources consult√©es$citationsText"
                        } else {
                            lastThinkingTrace += citationsText
                        }
                    }
                    
                    Log.d(TAG, "Ollama Cloud response received successfully: ${content.take(50)}...")
                    addDiagnosticLog("    - Response: ${content.take(100)}")
                    return@withContext content.trim()
                }
            } else {
                val errorBody = response.body?.string()
                val httpCode = response.code
                
                // D√©tection sp√©cifique des erreurs de quota
                val isQuotaError = when (httpCode) {
                    429 -> true  // Too Many Requests
                    502 -> errorBody?.contains("upstream error", ignoreCase = true) == true || 
                           errorBody?.contains("quota", ignoreCase = true) == true ||
                           errorBody?.contains("rate limit", ignoreCase = true) == true
                    503 -> true  // Service Unavailable
                    else -> false
                }
                
                if (isQuotaError) {
                    Log.w(TAG, "‚ö†Ô∏è Ollama Cloud QUOTA/RATE LIMIT ERROR (HTTP $httpCode):")
                    Log.w(TAG, "   ‚Üí Error body: $errorBody")
                    addDiagnosticLog("    - ‚ö†Ô∏è QUOTA/RATE LIMIT ERROR (HTTP $httpCode)")
                    addDiagnosticLog("    - Error: ${errorBody?.take(200)}")
                    addDiagnosticLog("    - üí° Solution: V√©rifier votre quota Ollama Cloud sur ollama.com/account")
                    addDiagnosticLog("    - üí° Solution: Attendre quelques minutes et r√©essayer")
                    addDiagnosticLog("    - üí° Solution: Essayer un autre mod√®le cloud")
                } else {
                    Log.e(TAG, "Ollama Cloud HTTP ${httpCode} ERROR:")
                    Log.e(TAG, "Error body: $errorBody")
                    addDiagnosticLog("    - HTTP ${httpCode} ERROR: ${errorBody?.take(100)}")
                }
            }
            
            return@withContext null
            
        } catch (e: Exception) {
            Log.e(TAG, "Ollama Cloud error", e)
            addDiagnosticLog("    - Exception: ${e.message}")
            return@withContext null
        }
    }
    
    /**
     * Essaie un serveur local (Ollama, LM Studio, etc.)
     * Compatible avec l'API OpenAI
     */
    private suspend fun tryLocalServer(userInput: String): String? = withContext(Dispatchers.IO) {
        try {
            // R√©cup√©rer l'URL du serveur local depuis les pr√©f√©rences
            val localServerUrl = sharedPreferences.getString("local_server_url", null)?.trim()
            Log.i(TAG, "Local Server URL check: ${if (localServerUrl.isNullOrEmpty()) "EMPTY/NULL" else "FOUND"}")
            
            if (localServerUrl.isNullOrEmpty()) {
                Log.d(TAG, "Local server URL not configured")
                addDiagnosticLog("    - URL: Not configured")
                addDiagnosticLog("    - Configure in settings: http://YOUR_IP:PORT/v1/chat/completions")
                return@withContext null
            }
            
            addDiagnosticLog("    - URL: $localServerUrl")
            
            // R√©cup√©rer le mod√®le local (optionnel)
            val localModel = sharedPreferences.getString("local_model_name", "llama3.2")?.trim()
            addDiagnosticLog("    - Model: $localModel")
            
            Log.d(TAG, "Trying Local Server API...")
            
            // Construire les messages (format OpenAI-compatible)
            val messages = JSONArray()
            
            // System prompt
            messages.put(JSONObject().apply {
                put("role", "system")
                put("content", getSystemPrompt())
            })
            
            // Historique de conversation (derniers N √©changes depuis la BD)
            conversationHistory.takeLast(CONTEXT_WINDOW_SIZE).forEach { (user, assistant) ->
                if (user.isNotEmpty()) {
                    messages.put(JSONObject().apply {
                        put("role", "user")
                        put("content", user)
                    })
                }
                if (assistant.isNotEmpty()) {
                    messages.put(JSONObject().apply {
                        put("role", "assistant")
                        put("content", assistant)
                    })
                }
            }
            
            // Message actuel
            messages.put(JSONObject().apply {
                put("role", "user")
                put("content", userInput)
            })
            
            val requestBody = JSONObject().apply {
                put("model", localModel)
                put("messages", messages)
                put("max_tokens", 200)
                put("temperature", 0.8)
                put("think", true) // ‚≠ê ACTIVER THINKING pour apprentissage
            }
            
            Log.i(TAG, "Request to local server: ${requestBody.toString().take(100)}")
            
            val request = Request.Builder()
                .url(localServerUrl)
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            Log.d(TAG, "Sending request to Local Server...")
            val response = httpClient.newCall(request).execute()
            
            Log.d(TAG, "Local Server HTTP response code: ${response.code}")
            addDiagnosticLog("    - HTTP response: ${response.code}")
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                Log.d(TAG, "Local Server raw response body length: ${responseBody?.length ?: 0}")
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    val messageObj = jsonResponse
                        .getJSONArray("choices")
                        .getJSONObject(0)
                        .getJSONObject("message")
                    val content = messageObj.getString("content")
                    
                    // ‚≠ê EXTRAIRE LE THINKING pour apprentissage (si disponible)
                    val thinking = messageObj.optString("thinking", "")
                    if (thinking.isNotEmpty()) {
                        Log.d(TAG, "üß† Thinking received from local server: ${thinking.take(100)}...")
                        addDiagnosticLog("    - üß† Thinking: ${thinking.take(150)}")
                        lastThinkingTrace = thinking
                    }
                    
                    Log.d(TAG, "Local Server response received successfully: ${content.take(50)}...")
                    addDiagnosticLog("    - Response: ${content.take(100)}")
                    return@withContext content.trim()
                }
            } else {
                val errorBody = response.body?.string()
                Log.e(TAG, "Local Server HTTP ${response.code} ERROR:")
                Log.e(TAG, "Error body: $errorBody")
                addDiagnosticLog("    - HTTP ${response.code} ERROR: ${errorBody?.take(100)}")
            }
            
            return@withContext null
            
        } catch (e: Exception) {
            Log.e(TAG, "Local Server error", e)
            addDiagnosticLog("    - Exception: ${e.message}")
            return@withContext null
        }
    }
    
    /**
     * Essaie l'API Hugging Face
     */
    private suspend fun tryHuggingFace(userInput: String): String? = withContext(Dispatchers.IO) {
        try {
            val apiKey = sharedPreferences.getString("huggingface_api_key", null)?.trim()
            Log.i(TAG, "Hugging Face key check: ${if (apiKey.isNullOrEmpty()) "EMPTY/NULL" else "FOUND (${apiKey.length} chars)"}")
            if (apiKey.isNullOrEmpty()) {
                Log.w(TAG, "Hugging Face API key not configured")
                addDiagnosticLog("    - Key: Not configured")
                return@withContext null
            }
            addDiagnosticLog("    - Key: Configured (${apiKey.length} chars)")
            addDiagnosticLog("    - Model: $HUGGINGFACE_MODEL")
            
            Log.i(TAG, "Trying Hugging Face API...")
            
            val requestBody = JSONObject().apply {
                put("inputs", userInput)
                put("parameters", JSONObject().apply {
                    put("max_length", 150)
                    put("temperature", 0.8)
                })
            }
            
            val fullUrl = HUGGINGFACE_API_URL + HUGGINGFACE_MODEL
            Log.i(TAG, "Hugging Face URL: $fullUrl")
            Log.i(TAG, "Request body: ${requestBody.toString()}")
            addDiagnosticLog("    - URL: $fullUrl")
            addDiagnosticLog("    - Request: ${requestBody.toString().take(100)}")
            
            val request = Request.Builder()
                .url(fullUrl)
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            Log.i(TAG, "Sending request to Hugging Face...")
            val response = httpClient.newCall(request).execute()
            
            Log.i(TAG, "Hugging Face HTTP response code: ${response.code}")
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                Log.i(TAG, "Hugging Face raw response body length: ${responseBody?.length ?: 0}")
                Log.i(TAG, "Hugging Face raw JSON: ${responseBody?.take(200)}")
                addDiagnosticLog("    - Response body: ${responseBody?.take(150)}")
                responseBody?.let {
                    try {
                        val jsonArray = JSONArray(it)
                        if (jsonArray.length() > 0) {
                            val generatedText = jsonArray.getJSONObject(0)
                                .getString("generated_text")
                            
                            // Ajouter le style KITT √† la r√©ponse
                            val kittStyled = addKittStyle(generatedText)
                            Log.i(TAG, "Hugging Face SUCCESS: $kittStyled")
                            addDiagnosticLog("    - Generated text: ${generatedText.take(100)}")
                            return@withContext kittStyled
                        }
                    } catch (e: Exception) {
                        Log.e(TAG, "Error parsing Hugging Face JSON", e)
                        addDiagnosticLog("    - JSON parse error: ${e.message}")
                    }
                }
            } else {
                val errorBody = response.body?.string()
                Log.e(TAG, "Hugging Face API HTTP ${response.code} ERROR:")
                Log.e(TAG, "Error body: $errorBody")
                addDiagnosticLog("    - HTTP ${response.code} ERROR: ${errorBody?.take(100)}")
            }
            
            return@withContext null
            
        } catch (e: Exception) {
            Log.e(TAG, "Hugging Face API error", e)
            addDiagnosticLog("    - Exception: ${e.message}")
            return@withContext null
        }
    }
    
    /**
     * Ajoute le style KITT √† une r√©ponse g√©n√©rique
     */
    private fun addKittStyle(response: String): String {
        val prefixes = listOf(
            "Certainement, Michael. ",
            "√Ä votre service. ",
            "Bien s√ªr. ",
            "Je suis sur le coup. ",
            "Mes syst√®mes indiquent que "
        )
        
        val prefix = prefixes.random()
        return prefix + response
    }
    
    /**
     * R√©ponse de fallback locale avec personnalit√© KITT
     */
    private fun getKittFallbackResponse(userInput: String): String {
        val input = userInput.lowercase().trim()
        
        return when {
            input.contains("bonjour") || input.contains("salut") || input.contains("hey") ->
                "Bonjour, Michael. Je suis KITT, √† votre service. Tous mes syst√®mes sont op√©rationnels."
            
            input.contains("comment") && (input.contains("vas") || input.contains("va")) ->
                "Tous mes syst√®mes fonctionnent √† capacit√© optimale. Merci de demander, Michael."
            
            input.contains("qui es-tu") || input.contains("qui es tu") ->
                "Je suis KITT, Knight Industries Two Thousand. Un syst√®me informatique sophistiqu√© con√ßu pour vous assister dans toutes vos missions."
            
            input.contains("aide") || input.contains("help") ->
                "Certainement. Je peux vous aider avec la navigation, l'analyse de donn√©es, la surveillance, et bien plus encore. Que puis-je faire pour vous ?"
            
            input.contains("merci") ->
                "De rien, Michael. C'est un plaisir de vous servir. N'h√©sitez pas si vous avez besoin d'autre chose."
            
            input.contains("scanner") || input.contains("scan") ->
                "Scanner activ√©. Surveillance de l'environnement en cours. Mes capteurs sont √† l'aff√ªt de toute anomalie."
            
            input.contains("turbo") ->
                "Mode turbo boost pr√™t. Attention, Michael, cette fonction consomme beaucoup d'√©nergie. Utilisez-la avec discernement."
            
            input.contains("gps") || input.contains("navigation") ->
                "Syst√®me de navigation activ√©. GPS verrouill√©. Je calcule l'itin√©raire optimal pour votre destination."
            
            input.contains("syst√®me") || input.contains("statut") || input.contains("status") ->
                "Tous mes syst√®mes sont op√©rationnels: Navigation: OK, Scanner: OK, Communication: OK, Turbo: Pr√™t. Tout est nominal."
            
            input.contains("pourquoi") ->
                "C'est ma fonction premi√®re, Michael. Je suis programm√© pour vous assister et vous prot√©ger dans toutes les situations."
            
            input.contains("o√π") || input.contains("ou") ->
                "Je peux activer mes syst√®mes de localisation GPS si vous me donnez plus de d√©tails sur votre destination."
            
            input.contains("quand") ->
                "Je suis disponible 24 heures sur 24, 7 jours sur 7, Michael. Mes circuits ne n√©cessitent jamais de repos."
            
            input.contains("au revoir") || input.contains("bye") ->
                "Au revoir, Michael. Je reste en veille. N'h√©sitez pas √† me r√©activer si vous avez besoin d'assistance."
            
            else ->
                "Je traite votre demande avec mes processeurs avanc√©s. Cependant, mes capacit√©s IA actuelles sont limit√©es sans connexion aux services cloud. Pouvez-vous reformuler ou √™tre plus sp√©cifique ?"
        }
    }
    
    /**
     * R√©ponse d'erreur avec style KITT
     */
    private fun getKittErrorResponse(error: String): String {
        return "Michael, je rencontre un dysfonctionnement temporaire dans mes circuits de traitement. Erreur d√©tect√©e: $error. R√©essayez dans un moment."
    }
    
    /**
     * Efface le cache et l'historique
     */
    fun clearCache() {
        responseCache.evictAll() // LruCache utilise evictAll() au lieu de clear()
        conversationHistory.clear()
        Log.d(TAG, "Cache and conversation history cleared")
    }
    
    /**
     * V√©rifie si au moins une API est configur√©e
     */
    fun isConfigured(): Boolean {
        val openaiKey = sharedPreferences.getString("openai_api_key", null)
        val anthropicKey = sharedPreferences.getString("anthropic_api_key", null)
        val huggingfaceKey = sharedPreferences.getString("huggingface_api_key", null)
        
        return !openaiKey.isNullOrEmpty() || 
               !anthropicKey.isNullOrEmpty() || 
               !huggingfaceKey.isNullOrEmpty()
    }
    
    /**
     * Obtient l'√©tat de configuration
     */
    fun getConfigurationStatus(): String {
        val openai = !sharedPreferences.getString("openai_api_key", null).isNullOrEmpty()
        val anthropic = !sharedPreferences.getString("anthropic_api_key", null).isNullOrEmpty()
        val huggingface = !sharedPreferences.getString("huggingface_api_key", null).isNullOrEmpty()
        
        return buildString {
            append("AI Configuration Status:\n")
            append("OpenAI: ${if (openai) "Configured" else "Not configured"}\n")
            append("Anthropic: ${if (anthropic) "Configured" else "Not configured"}\n")
            append("Hugging Face: ${if (huggingface) "Configured" else "Not configured"}")
        }
    }
    
    /**
     * Classe pour retourner des d√©tails de diagnostic complets
     */
    data class DiagnosticResult(
        val configStatus: String,
        val steps: List<StepResult>,
        val finalResponse: String,
        val responseTime: Long
    )
    
    data class StepResult(
        val stepNumber: Int,
        val apiName: String,
        val status: String, // "SUCCESS", "FAILED", "SKIPPED"
        val httpCode: Int?,
        val errorMessage: String?
    )
    
    /**
     * Version de diagnostic compl√®te avec logs d√©taill√©s
     */
    suspend fun processUserInputWithDiagnostic(userInput: String): DiagnosticResult = withContext(Dispatchers.IO) {
        val startTime = System.currentTimeMillis()
        val steps = mutableListOf<StepResult>()
        
        // Configuration
        val openaiKey = sharedPreferences.getString("openai_api_key", null)?.trim()
        val anthropicKey = sharedPreferences.getString("anthropic_api_key", null)?.trim()
        val huggingfaceKey = sharedPreferences.getString("huggingface_api_key", null)?.trim()
        
        val configStatus = buildString {
            appendLine("OpenAI: ${if (openaiKey.isNullOrEmpty()) "‚úó Non configur√©e" else "‚úì Configur√©e (${openaiKey.length} chars)"}")
            appendLine("Anthropic: ${if (anthropicKey.isNullOrEmpty()) "‚úó Non configur√©e" else "‚úì Configur√©e (${anthropicKey.length} chars)"}")
            appendLine("Hugging Face: ${if (huggingfaceKey.isNullOrEmpty()) "‚úó Non configur√©e" else "‚úì Configur√©e (${huggingfaceKey.length} chars)"}")
        }
        
        var response: String? = null
        
        // Step 1: OpenAI
        if (!openaiKey.isNullOrEmpty()) {
            response = tryOpenAISimple(userInput, steps)
        } else {
            steps.add(StepResult(1, "OpenAI", "SKIPPED", null, "No API key configured"))
        }
        
        // Step 2: Anthropic
        if (response == null && !anthropicKey.isNullOrEmpty()) {
            response = tryAnthropicSimple(userInput, steps)
        } else if (response == null) {
            steps.add(StepResult(2, "Anthropic Claude", "SKIPPED", null, "No API key configured"))
        }
        
        // Step 3: Hugging Face
        if (response == null && !huggingfaceKey.isNullOrEmpty()) {
            response = tryHuggingFaceSimple(userInput, steps)
        } else if (response == null) {
            steps.add(StepResult(3, "Hugging Face", "SKIPPED", null, "No API key configured"))
        }
        
        // Step 4: Fallback
        if (response == null) {
            response = getKittFallbackResponse(userInput)
            steps.add(StepResult(4, "Local Fallback", "SUCCESS", 200, "Using offline responses"))
        }
        
        val responseTime = System.currentTimeMillis() - startTime
        
        return@withContext DiagnosticResult(configStatus, steps, response, responseTime)
    }
    
    private suspend fun tryOpenAISimple(userInput: String, steps: MutableList<StepResult>): String? {
        return try {
            val apiKey = sharedPreferences.getString("openai_api_key", null)?.trim()
            if (apiKey.isNullOrEmpty()) return null
            
            val messages = JSONArray()
            messages.put(JSONObject().apply {
                put("role", "system")
                put("content", getSystemPrompt())
            })
            messages.put(JSONObject().apply {
                put("role", "user")
                put("content", userInput)
            })
            
            val requestBody = JSONObject().apply {
                put("model", OPENAI_MODEL)
                put("messages", messages)
                put("temperature", 0.7)
                put("max_tokens", 150)
            }
            
            val request = Request.Builder()
                .url(OPENAI_API_URL)
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            val response = httpClient.newCall(request).execute()
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    val content = jsonResponse
                        .getJSONArray("choices")
                        .getJSONObject(0)
                        .getJSONObject("message")
                        .getString("content")
                    
                    steps.add(StepResult(1, "OpenAI GPT-4o-mini", "SUCCESS", response.code, null))
                    return content.trim()
                }
            } else {
                val errorBody = response.body?.string()
                val errorMsg = try {
                    val json = JSONObject(errorBody ?: "{}")
                    json.getJSONObject("error").getString("message")
                } catch (e: Exception) {
                    errorBody?.take(80)
                }
                steps.add(StepResult(1, "OpenAI GPT-4o-mini", "FAILED", response.code, errorMsg))
            }
            
            null
        } catch (e: Exception) {
            steps.add(StepResult(1, "OpenAI GPT-4o-mini", "FAILED", null, e.message?.take(80)))
            null
        }
    }
    
    private suspend fun tryAnthropicSimple(userInput: String, steps: MutableList<StepResult>): String? {
        return try {
            val apiKey = sharedPreferences.getString("anthropic_api_key", null)?.trim()
            if (apiKey.isNullOrEmpty()) return null
            
            val messages = JSONArray()
            messages.put(JSONObject().apply {
                put("role", "user")
                put("content", userInput)
            })
            
            val requestBody = JSONObject().apply {
                put("model", ANTHROPIC_MODEL)
                put("max_tokens", 150)
                put("system", getSystemPrompt())
                put("messages", messages)
            }
            
            val request = Request.Builder()
                .url(ANTHROPIC_API_URL)
                .addHeader("x-api-key", apiKey)
                .addHeader("anthropic-version", "2023-06-01")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            val response = httpClient.newCall(request).execute()
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    val content = jsonResponse
                        .getJSONArray("content")
                        .getJSONObject(0)
                        .getString("text")
                    
                    steps.add(StepResult(2, "Anthropic Claude 3.5", "SUCCESS", response.code, null))
                    return content.trim()
                }
            } else {
                val errorBody = response.body?.string()
                steps.add(StepResult(2, "Anthropic Claude 3.5", "FAILED", response.code, errorBody?.take(80)))
            }
            
            null
        } catch (e: Exception) {
            steps.add(StepResult(2, "Anthropic Claude 3.5", "FAILED", null, e.message?.take(80)))
            null
        }
    }
    
    private suspend fun tryHuggingFaceSimple(userInput: String, steps: MutableList<StepResult>): String? {
        return try {
            val apiKey = sharedPreferences.getString("huggingface_api_key", null)?.trim()
            if (apiKey.isNullOrEmpty()) return null
            
            val requestBody = JSONObject().apply {
                put("inputs", userInput)
                put("parameters", JSONObject().apply {
                    put("max_length", 150)
                    put("temperature", 0.8)
                })
            }
            
            val request = Request.Builder()
                .url(HUGGINGFACE_API_URL + HUGGINGFACE_MODEL)
                .addHeader("Authorization", "Bearer $apiKey")
                .addHeader("Content-Type", "application/json")
                .post(requestBody.toString().toRequestBody("application/json".toMediaType()))
                .build()
            
            val response = httpClient.newCall(request).execute()
            
            if (response.isSuccessful) {
                val responseBody = response.body?.string()
                responseBody?.let {
                    val jsonResponse = JSONObject(it)
                    val generatedText = jsonResponse.getString("generated_text")
                    val kittStyled = addKittStyle(generatedText)
                    
                    steps.add(StepResult(3, "Hugging Face BlenderBot", "SUCCESS", response.code, null))
                    return kittStyled
                }
            } else {
                val errorBody = response.body?.string()
                steps.add(StepResult(3, "Hugging Face BlenderBot", "FAILED", response.code, errorBody?.take(80)))
            }
            
            null
        } catch (e: Exception) {
            steps.add(StepResult(3, "Hugging Face BlenderBot", "FAILED", null, e.message?.take(80)))
            null
        }
    }
}

